{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
    "train = datasets.MNIST('.', train= True, download= True, transform= transforms)\n",
    "test = datasets.MNIST('.', train= False, download= True, transform=transforms)\n",
    "train_loader = DataLoader(train, batch_size=64, shuffle= True)\n",
    "test_loader = DataLoader(test, batch_size= 64, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1, 32, kernel_size=3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride= 2),\n",
    "                                 nn.Conv2d(32, 64, kernel_size=3), \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride=2),\n",
    "                                 nn.Conv2d(64, 32, kernel_size= 3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride= 2))\n",
    "        self.classify_head = nn.Sequential(nn.Linear(32, 20, bias= True),\n",
    "                                           nn.Linear(20, 10, bias= True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classify_head(self.net(x).reshape(-1, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classify_head): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=20, bias=True)\n",
       "    (1): Linear(in_features=20, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0, loss = 2160.6764454841614\n",
      "Epoch - 1, loss = 2149.515485048294\n",
      "Epoch - 2, loss = 2136.6926374435425\n",
      "Epoch - 3, loss = 2117.1690723896027\n",
      "Epoch - 4, loss = 2081.1246058940887\n",
      "Epoch - 5, loss = 2002.1716482639313\n",
      "Epoch - 6, loss = 1804.4552952051163\n",
      "Epoch - 7, loss = 1374.0778160095215\n",
      "Epoch - 8, loss = 930.1589660644531\n",
      "Epoch - 9, loss = 681.560250043869\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch - {epoch}, loss = {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '../lab 6/ModelFiles/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 904    0    4    0    4   16   49    1    1    1]\n",
      " [   0 1112    3    1    0    3    2    3   11    0]\n",
      " [   1    9  854   16    7    9   13   36   76   11]\n",
      " [   0    1   17  932    0   15    0   14   18   13]\n",
      " [   2    4    0    0  870    4   39    4    9   50]\n",
      " [   6    9    2   25    3  760   29    5   26   27]\n",
      " [  50    7    3    0   48   17  824    0    8    1]\n",
      " [   4    5   56   31   14    3    1  863   15   36]\n",
      " [   0   10   26   28    5   56   14   15  749   71]\n",
      " [   7    5    3   17   33   26    8   34   34  842]]\n",
      "38150\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        output = model(input)\n",
    "        val, index = torch.max(output, 1)\n",
    "        all_preds.extend(index)\n",
    "        all_labels.extend(target)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(cm)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
