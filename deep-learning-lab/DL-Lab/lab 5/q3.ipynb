{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
    "train = datasets.MNIST('.', train= True, download= True, transform= transforms)\n",
    "test = datasets.MNIST('.', train= False, download= True, transform= transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size= 64, shuffle= True)\n",
    "test_loader = DataLoader(test, batch_size= 64, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1, 64, kernel_size=3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride=2),\n",
    "                                 nn.Conv2d(64, 128, kernel_size=3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride=2),\n",
    "                                 nn.Conv2d(128, 64, kernel_size=3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride=2))\n",
    "        self.classify_head = nn.Sequential(nn.Linear(64, 20, bias= True),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(20, 10, bias=True))\n",
    "    def forward(self, x):\n",
    "        features = self.net(x)\n",
    "        # the -1 in reshape is for infering the batch size\n",
    "        return self.classify_head(features.reshape(-1, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0, loss = 2154.909630060196\n",
      "Epoch - 1, loss = 2140.0478971004486\n",
      "Epoch - 2, loss = 2119.7958755493164\n",
      "Epoch - 3, loss = 2083.61563038826\n",
      "Epoch - 4, loss = 2007.311164855957\n",
      "Epoch - 5, loss = 1826.4274609088898\n",
      "Epoch - 6, loss = 1403.7756037712097\n",
      "Epoch - 7, loss = 926.8690323829651\n",
      "Epoch - 8, loss = 652.020500510931\n",
      "Epoch - 9, loss = 497.1380241513252\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch - {epoch}, loss = {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 930    0    8    0    1    9   19    5    5    3]\n",
      " [   0 1097    2    3    0   10    2    1   20    0]\n",
      " [  10    1  884   33    6   12    8   28   33   17]\n",
      " [   0    2   36  883    0   50    0   20   13    6]\n",
      " [   2    4    0    0  902    1   29    1    3   40]\n",
      " [   7   13    6   27   33  708   15   20   51   12]\n",
      " [  16    5    2    0   33    6  890    0    6    0]\n",
      " [   4    4   41   56    0    6    0  876    3   38]\n",
      " [   3   14   10   46   15   48   14    6  776   42]\n",
      " [  11    7    4    9   54   49    3   21   12  839]]\n",
      "149798\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        output = model(input)\n",
    "        val, index = torch.max(output, 1)\n",
    "        all_preds.extend(index)\n",
    "        all_labels.extend(target)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(cm)\n",
    "# remember that model.parameters needs () after it\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
