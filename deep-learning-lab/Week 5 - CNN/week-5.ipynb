{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2451b503-8b08-4cea-ae6f-c82d7899d3dd",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "Implement convolution operation for a sample image of shape (H=6, W=6, C=1) with a\n",
    "random kernel of size (3,3) using torch.nn.functional.conv2d. \n",
    "\n",
    "What is the dimension of the output image? Apply, various values for parameter stride=1 and note the change in the dimension of the output image. Arrive at an equation for the output image size with respect to the kernel size and stride and verify your answer with code. Now, repeat the exercise by changing padding parameter. Obtain a formula using kernel, stride, and padding to get the output image size. What is the total number of parameters in your network? Verify with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63beb18-756e-4d29-8b0c-b9573e28f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[0.5789, 0.5020, 0.1524, 0.6935, 0.5461, 0.7108],\n",
      "        [0.1845, 0.9184, 0.3430, 0.9406, 0.2525, 0.9390],\n",
      "        [0.5949, 0.0434, 0.5070, 0.1027, 0.8809, 0.4918],\n",
      "        [0.7802, 0.6744, 0.3875, 0.3606, 0.3425, 0.2095],\n",
      "        [0.0884, 0.2588, 0.1794, 0.6549, 0.0683, 0.7155],\n",
      "        [0.8711, 0.5248, 0.8396, 0.9874, 0.2827, 0.2234]])\n",
      "image.shape= torch.Size([1, 6, 6])\n",
      "image.shape= torch.Size([1, 1, 6, 6])\n",
      "image= tensor([[[[0.5789, 0.5020, 0.1524, 0.6935, 0.5461, 0.7108],\n",
      "          [0.1845, 0.9184, 0.3430, 0.9406, 0.2525, 0.9390],\n",
      "          [0.5949, 0.0434, 0.5070, 0.1027, 0.8809, 0.4918],\n",
      "          [0.7802, 0.6744, 0.3875, 0.3606, 0.3425, 0.2095],\n",
      "          [0.0884, 0.2588, 0.1794, 0.6549, 0.0683, 0.7155],\n",
      "          [0.8711, 0.5248, 0.8396, 0.9874, 0.2827, 0.2234]]]])\n",
      "kernel= tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "outimage= tensor([[[[3.8246, 4.2031, 4.4188, 5.5580],\n",
      "          [4.4335, 4.2777, 4.1173, 4.5201],\n",
      "          [3.5141, 3.1688, 3.4839, 3.8267],\n",
      "          [4.6043, 4.8676, 4.1030, 3.8449]]]])\n",
      "Dimension of output image S-1 P-0:  torch.Size([1, 1, 4, 4])\n",
      "Manually dim of output S-1 P-0:  [1, 1, 4, 4]\n",
      "Dimension of output image S-1 P-1: torch.Size([1, 1, 6, 6])\n",
      "Manually dim of output S-1 P-1:  [3, 3, 6, 6]\n",
      "Dimension of output image S-1 P-2: torch.Size([1, 1, 8, 8])\n",
      "Manually dim of output S-1 P-2:  [5, 5, 8, 8]\n",
      "Dimension of output image S-2 P-1:  torch.Size([1, 1, 3, 3])\n",
      "Manually dim of output S-2 P-1:  [2, 2, 3, 3]\n",
      "Dimension of output image S-2 P-1: torch.Size([1, 1, 2, 2])\n",
      "Manually dim of output S-3 P-1:  [1, 1, 2, 2]\n",
      "Number of Learnable Parameters = 9\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image = torch.rand(6,6)\n",
    "print(\"image=\", image)\n",
    "#Add a new dimension along 0th dimension\n",
    "#i.e. (6,6) becomes (1,6,6). This is because\n",
    "#pytorch expects the input to conv2D as 4d tensor\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "print(\"image=\", image)\n",
    "kernel = torch.ones(3,3)\n",
    "#kernel = torch.rand(3,3)\n",
    "print(\"kernel=\", kernel)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "\n",
    "def out_dim(in_shape,stride,padding,kernel_shape):\n",
    "    out_shape = [0 for i in range(4)]\n",
    "    for dim in range(len(in_shape)):\n",
    "        out_shape[dim] = (in_shape[dim] + 2*padding - kernel_shape[dim])//stride + 1\n",
    "    return out_shape\n",
    "    \n",
    "#Stride 1 Padding 0\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=0)\n",
    "print(\"outimage=\", outimage)\n",
    "print(\"Dimension of output image S-1 P-0: \",outimage.shape)\n",
    "print(\"Manually dim of output S-1 P-0: \",out_dim(image.shape,1,0,kernel.shape))\n",
    "\n",
    "#Stride 1 Padding 1\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=1)\n",
    "print(\"Dimension of output image S-1 P-1:\",outimage.shape)\n",
    "print(\"Manually dim of output S-1 P-1: \",out_dim(image.shape,1,1,kernel.shape))\n",
    "\n",
    "#Stride 1 Padding 2\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=2)\n",
    "print(\"Dimension of output image S-1 P-2:\",outimage.shape)\n",
    "print(\"Manually dim of output S-1 P-2: \",out_dim(image.shape,1,2,kernel.shape))\n",
    "\n",
    "#Stride 2 Padding 1\n",
    "outimage = F.conv2d(image, kernel, stride=2, padding=1)\n",
    "print(\"Dimension of output image S-2 P-1: \",outimage.shape)\n",
    "print(\"Manually dim of output S-2 P-1: \",out_dim(image.shape,2,1,kernel.shape))\n",
    "\n",
    "#Stride 3 Padding 1\n",
    "outimage = F.conv2d(image, kernel, stride=3, padding=1)\n",
    "print(\"Dimension of output image S-2 P-1:\",outimage.shape)\n",
    "print(\"Manually dim of output S-3 P-1: \",out_dim(image.shape,3,1,kernel.shape))\n",
    "\n",
    "print(\"Number of Learnable Parameters = 9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eced408-fccf-4442-8cb5-a40b2b86f7c6",
   "metadata": {},
   "source": [
    "## Q2 \n",
    "\n",
    "Apply torch.nn.Conv2d to the input image of Qn 1 with out-channel=3 and observe the\n",
    "output. Implement the equivalent of torch.nn.Conv2d using the torch.nn.functional.conv2D\n",
    "to get the same output. You may ignore bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b074b7-75ad-4ae6-bb2d-10f72b6a15d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel parameters for 3 channels: \n",
      "Parameter containing:\n",
      "tensor([[[[-0.3063, -0.1800,  0.0899],\n",
      "          [-0.1401,  0.0161,  0.3330],\n",
      "          [ 0.2041,  0.0124,  0.1391]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1298,  0.1129,  0.0200],\n",
      "          [ 0.1756, -0.2942,  0.1395],\n",
      "          [ 0.0793, -0.0007,  0.0210]]],\n",
      "\n",
      "\n",
      "        [[[-0.1458,  0.0738,  0.0407],\n",
      "          [ 0.1321,  0.1240, -0.2490],\n",
      "          [ 0.1988, -0.0943, -0.1842]]]], requires_grad=True)\n",
      "Output image using torch.nn.Conv2d: \n",
      "tensor([[[[-0.0005,  0.0172,  0.2629,  0.2263],\n",
      "          [ 0.0153,  0.3399,  0.1179,  0.1983],\n",
      "          [ 0.0219,  0.1353, -0.1438,  0.1420],\n",
      "          [ 0.0858,  0.1977,  0.1055,  0.1304]],\n",
      "\n",
      "         [[ 0.1736,  0.4452,  0.0053,  0.2713],\n",
      "          [ 0.4316,  0.0469,  0.1377,  0.4205],\n",
      "          [ 0.1936,  0.1905,  0.2136,  0.2782],\n",
      "          [ 0.2201,  0.2862,  0.2036,  0.2633]],\n",
      "\n",
      "         [[ 0.2135, -0.4064, -0.0213, -0.0295],\n",
      "          [-0.2009, -0.2047,  0.1323, -0.2521],\n",
      "          [-0.0569,  0.0067, -0.1313, -0.1563],\n",
      "          [-0.0040, -0.1216, -0.0733,  0.0130]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Output image using torch.nn.functional.conv2d: \n",
      "tensor([[[[-0.0005,  0.0172,  0.2629,  0.2263],\n",
      "          [ 0.0153,  0.3399,  0.1179,  0.1983],\n",
      "          [ 0.0219,  0.1353, -0.1438,  0.1420],\n",
      "          [ 0.0858,  0.1977,  0.1055,  0.1304]],\n",
      "\n",
      "         [[ 0.1736,  0.4452,  0.0053,  0.2713],\n",
      "          [ 0.4316,  0.0469,  0.1377,  0.4205],\n",
      "          [ 0.1936,  0.1905,  0.2136,  0.2782],\n",
      "          [ 0.2201,  0.2862,  0.2036,  0.2633]],\n",
      "\n",
      "         [[ 0.2135, -0.4064, -0.0213, -0.0295],\n",
      "          [-0.2009, -0.2047,  0.1323, -0.2521],\n",
      "          [-0.0569,  0.0067, -0.1313, -0.1563],\n",
      "          [-0.0040, -0.1216, -0.0733,  0.0130]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "image= torch.tensor([[[[0.2557, 0.9236, 0.4913, 0.3200, 0.4958, 0.2214],\n",
    "          [0.7554, 0.6501, 0.0107, 0.8675, 0.5163, 0.6102],\n",
    "          [0.8228, 0.1919, 0.8724, 0.8043, 0.3882, 0.9689],\n",
    "          [0.4894, 0.5116, 0.5624, 0.6949, 0.6289, 0.9802],\n",
    "          [0.3913, 0.2773, 0.1427, 0.3717, 0.4154, 0.3669],\n",
    "          [0.8327, 0.8157, 0.7192, 0.9387, 0.4569, 0.6776]]]])\n",
    "\n",
    "conv = nn.Conv2d(in_channels=1,out_channels=3,kernel_size=3,stride=1,padding=0,bias=False)\n",
    "print(\"Kernel parameters for 3 channels: \")\n",
    "kernel = conv.weight\n",
    "print(conv.weight)\n",
    "print(\"Output image using torch.nn.Conv2d: \")\n",
    "out_image = print(conv(image))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "out_image = F.conv2d(image,kernel,stride=1,padding=0)\n",
    "print(\"Output image using torch.nn.functional.conv2d: \")\n",
    "print(out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e426921-6471-48ed-b498-9017accd3932",
   "metadata": {},
   "source": [
    "## Q3 \n",
    "\n",
    "Implement CNN for classifying digits in MNIST dataset using PyTorch. Display the classification accuracy in the form of a Confusion matrix. Verify the number of learnable parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4dd0e-3792-417b-ab9c-c356feefb3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "[1,   100] loss: 2.307\n",
      "[1,   200] loss: 2.294\n",
      "[1,   300] loss: 2.283\n",
      "[1,   400] loss: 2.264\n",
      "[1,   500] loss: 2.227\n",
      "[1,   600] loss: 2.158\n",
      "[1,   700] loss: 1.977\n",
      "[1,   800] loss: 1.674\n",
      "[1,   900] loss: 1.288\n",
      "[1,  1000] loss: 0.963\n",
      "[1,  1100] loss: 0.788\n",
      "[1,  1200] loss: 0.655\n",
      "[2,   100] loss: 0.583\n",
      "[2,   200] loss: 0.518\n",
      "[2,   300] loss: 0.476\n",
      "[2,   400] loss: 0.428\n",
      "[2,   500] loss: 0.383\n",
      "[2,   600] loss: 0.369\n",
      "[2,   700] loss: 0.335\n",
      "[2,   800] loss: 0.322\n",
      "[2,   900] loss: 0.304\n",
      "[2,  1000] loss: 0.286\n",
      "[2,  1100] loss: 0.280\n",
      "[2,  1200] loss: 0.269\n",
      "[3,   100] loss: 0.251\n",
      "[3,   200] loss: 0.220\n",
      "[3,   300] loss: 0.251\n",
      "[3,   400] loss: 0.225\n",
      "[3,   500] loss: 0.229\n",
      "[3,   600] loss: 0.235\n",
      "[3,   700] loss: 0.227\n",
      "[3,   800] loss: 0.217\n",
      "[3,   900] loss: 0.201\n",
      "[3,  1000] loss: 0.192\n",
      "[3,  1100] loss: 0.185\n",
      "[3,  1200] loss: 0.181\n",
      "[4,   100] loss: 0.191\n",
      "[4,   200] loss: 0.174\n",
      "[4,   300] loss: 0.184\n",
      "[4,   400] loss: 0.160\n",
      "[4,   500] loss: 0.188\n",
      "[4,   600] loss: 0.157\n",
      "[4,   700] loss: 0.155\n",
      "[4,   800] loss: 0.151\n",
      "[4,   900] loss: 0.166\n",
      "[4,  1000] loss: 0.151\n",
      "[4,  1100] loss: 0.147\n",
      "[4,  1200] loss: 0.165\n",
      "[5,   100] loss: 0.149\n",
      "[5,   200] loss: 0.131\n",
      "[5,   300] loss: 0.136\n",
      "[5,   400] loss: 0.134\n",
      "[5,   500] loss: 0.139\n",
      "[5,   600] loss: 0.136\n",
      "[5,   700] loss: 0.142\n",
      "[5,   800] loss: 0.133\n",
      "[5,   900] loss: 0.144\n",
      "[5,  1000] loss: 0.133\n",
      "[5,  1100] loss: 0.127\n",
      "[5,  1200] loss: 0.117\n",
      "[6,   100] loss: 0.118\n",
      "[6,   200] loss: 0.134\n",
      "[6,   300] loss: 0.109\n",
      "[6,   400] loss: 0.119\n",
      "[6,   500] loss: 0.114\n",
      "[6,   600] loss: 0.117\n",
      "[6,   700] loss: 0.116\n",
      "[6,   800] loss: 0.124\n",
      "[6,   900] loss: 0.110\n",
      "[6,  1000] loss: 0.112\n",
      "[6,  1100] loss: 0.113\n",
      "[6,  1200] loss: 0.111\n",
      "Finished Training. Final loss = 0.12786352634429932, Total params = 149798\n",
      "Correct = 9714, Total = 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(64,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(128,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(64,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNClassifier().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "correct,total = 0,0\n",
    "for i,vdata in enumerate(test_loader):\n",
    "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "    toutputs = model(tinputs)\n",
    "\n",
    "    _,predicted = torch.max(toutputs,1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted==tlabels).sum()\n",
    "        \n",
    "print(f\"Correct = {correct}, Total = {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5a7d9-ed64-4d1d-ab72-ed8c580a6cc9",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Modify CNN of Qn. 3 to reduce the number of parameters in the network. Draw a plot of\n",
    "percentage drop in parameters vs accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50ee7e0-4821-4662-ad21-4f671aa6744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.311\n",
      "[1,   200] loss: 2.298\n",
      "[1,   300] loss: 2.283\n",
      "[1,   400] loss: 2.270\n",
      "[1,   500] loss: 2.248\n",
      "[1,   600] loss: 2.207\n",
      "[1,   700] loss: 2.122\n",
      "[1,   800] loss: 1.930\n",
      "[1,   900] loss: 1.605\n",
      "[1,  1000] loss: 1.247\n",
      "[1,  1100] loss: 1.006\n",
      "[1,  1200] loss: 0.833\n",
      "[2,   100] loss: 0.753\n",
      "[2,   200] loss: 0.671\n",
      "[2,   300] loss: 0.623\n",
      "[2,   400] loss: 0.549\n",
      "[2,   500] loss: 0.500\n",
      "[2,   600] loss: 0.477\n",
      "[2,   700] loss: 0.480\n",
      "[2,   800] loss: 0.438\n",
      "[2,   900] loss: 0.416\n",
      "[2,  1000] loss: 0.400\n",
      "[2,  1100] loss: 0.379\n",
      "[2,  1200] loss: 0.380\n",
      "[3,   100] loss: 0.339\n",
      "[3,   200] loss: 0.376\n",
      "[3,   300] loss: 0.337\n",
      "[3,   400] loss: 0.315\n",
      "[3,   500] loss: 0.310\n",
      "[3,   600] loss: 0.314\n",
      "[3,   700] loss: 0.296\n",
      "[3,   800] loss: 0.279\n",
      "[3,   900] loss: 0.291\n",
      "[3,  1000] loss: 0.277\n",
      "[3,  1100] loss: 0.263\n",
      "[3,  1200] loss: 0.256\n",
      "[4,   100] loss: 0.255\n",
      "[4,   200] loss: 0.255\n",
      "[4,   300] loss: 0.257\n",
      "[4,   400] loss: 0.237\n",
      "[4,   500] loss: 0.252\n",
      "[4,   600] loss: 0.240\n",
      "[4,   700] loss: 0.234\n",
      "[4,   800] loss: 0.251\n",
      "[4,   900] loss: 0.228\n",
      "[4,  1000] loss: 0.220\n",
      "[4,  1100] loss: 0.209\n",
      "[4,  1200] loss: 0.217\n",
      "[5,   100] loss: 0.211\n",
      "[5,   200] loss: 0.214\n",
      "[5,   300] loss: 0.193\n",
      "[5,   400] loss: 0.203\n",
      "[5,   500] loss: 0.206\n",
      "[5,   600] loss: 0.197\n",
      "[5,   700] loss: 0.206\n",
      "[5,   800] loss: 0.176\n",
      "[5,   900] loss: 0.205\n",
      "[5,  1000] loss: 0.197\n",
      "[5,  1100] loss: 0.197\n",
      "[5,  1200] loss: 0.194\n",
      "[6,   100] loss: 0.191\n",
      "[6,   200] loss: 0.176\n",
      "[6,   300] loss: 0.187\n",
      "[6,   400] loss: 0.186\n",
      "[6,   500] loss: 0.183\n",
      "[6,   600] loss: 0.174\n",
      "[6,   700] loss: 0.174\n",
      "[6,   800] loss: 0.168\n",
      "[6,   900] loss: 0.173\n",
      "[6,  1000] loss: 0.157\n",
      "[6,  1100] loss: 0.160\n",
      "[6,  1200] loss: 0.162\n",
      "Finished Training. Final loss = 0.2445487082004547, Total params = 9594\n",
      "Correct = 9560, Total = 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CNNClassifier1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,16,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(16,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(32,16,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(16,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1 = CNNClassifier1().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model1.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model1(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "correct,total = 0,0\n",
    "for i,vdata in enumerate(test_loader):\n",
    "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "    toutputs = model1(tinputs)\n",
    "\n",
    "    _,predicted = torch.max(toutputs,1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted==tlabels).sum()\n",
    "        \n",
    "print(f\"Correct = {correct}, Total = {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c000d6-9bbc-4796-bf88-f31189c20dc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.314\n",
      "[1,   200] loss: 2.309\n",
      "[1,   300] loss: 2.301\n",
      "[1,   400] loss: 2.297\n",
      "[1,   500] loss: 2.292\n",
      "[1,   600] loss: 2.283\n",
      "[1,   700] loss: 2.273\n",
      "[1,   800] loss: 2.255\n",
      "[1,   900] loss: 2.214\n",
      "[1,  1000] loss: 2.135\n",
      "[1,  1100] loss: 1.924\n",
      "[1,  1200] loss: 1.642\n",
      "[2,   100] loss: 1.346\n",
      "[2,   200] loss: 1.070\n",
      "[2,   300] loss: 0.860\n",
      "[2,   400] loss: 0.719\n",
      "[2,   500] loss: 0.598\n",
      "[2,   600] loss: 0.545\n",
      "[2,   700] loss: 0.467\n",
      "[2,   800] loss: 0.422\n",
      "[2,   900] loss: 0.404\n",
      "[2,  1000] loss: 0.385\n",
      "[2,  1100] loss: 0.365\n",
      "[2,  1200] loss: 0.347\n",
      "[3,   100] loss: 0.295\n",
      "[3,   200] loss: 0.295\n",
      "[3,   300] loss: 0.265\n",
      "[3,   400] loss: 0.282\n",
      "[3,   500] loss: 0.263\n",
      "[3,   600] loss: 0.253\n",
      "[3,   700] loss: 0.236\n",
      "[3,   800] loss: 0.250\n",
      "[3,   900] loss: 0.233\n",
      "[3,  1000] loss: 0.232\n",
      "[3,  1100] loss: 0.216\n",
      "[3,  1200] loss: 0.217\n",
      "[4,   100] loss: 0.201\n",
      "[4,   200] loss: 0.210\n",
      "[4,   300] loss: 0.192\n",
      "[4,   400] loss: 0.193\n",
      "[4,   500] loss: 0.181\n",
      "[4,   600] loss: 0.174\n",
      "[4,   700] loss: 0.173\n",
      "[4,   800] loss: 0.187\n",
      "[4,   900] loss: 0.179\n",
      "[4,  1000] loss: 0.166\n",
      "[4,  1100] loss: 0.175\n",
      "[4,  1200] loss: 0.173\n",
      "[5,   100] loss: 0.163\n",
      "[5,   200] loss: 0.146\n",
      "[5,   300] loss: 0.155\n",
      "[5,   400] loss: 0.159\n",
      "[5,   500] loss: 0.147\n",
      "[5,   600] loss: 0.149\n",
      "[5,   700] loss: 0.140\n",
      "[5,   800] loss: 0.147\n",
      "[5,   900] loss: 0.144\n",
      "[5,  1000] loss: 0.132\n",
      "[5,  1100] loss: 0.132\n",
      "[5,  1200] loss: 0.133\n",
      "[6,   100] loss: 0.135\n",
      "[6,   200] loss: 0.119\n",
      "[6,   300] loss: 0.115\n",
      "[6,   400] loss: 0.127\n",
      "[6,   500] loss: 0.135\n",
      "[6,   600] loss: 0.136\n",
      "[6,   700] loss: 0.117\n",
      "[6,   800] loss: 0.110\n",
      "[6,   900] loss: 0.128\n",
      "[6,  1000] loss: 0.117\n",
      "[6,  1100] loss: 0.122\n",
      "[6,  1200] loss: 0.117\n",
      "Finished Training. Final loss = 0.08510205894708633, Total params = 601254\n",
      "[1,   100] loss: 2.308\n",
      "[1,   200] loss: 2.305\n",
      "[1,   300] loss: 2.304\n",
      "[1,   400] loss: 2.303\n",
      "[1,   500] loss: 2.299\n",
      "[1,   600] loss: 2.296\n",
      "[1,   700] loss: 2.291\n",
      "[1,   800] loss: 2.284\n",
      "[1,   900] loss: 2.272\n",
      "[1,  1000] loss: 2.256\n",
      "[1,  1100] loss: 2.233\n",
      "[1,  1200] loss: 2.193\n",
      "[2,   100] loss: 2.112\n",
      "[2,   200] loss: 1.941\n",
      "[2,   300] loss: 1.619\n",
      "[2,   400] loss: 1.206\n",
      "[2,   500] loss: 1.001\n",
      "[2,   600] loss: 0.904\n",
      "[2,   700] loss: 0.751\n",
      "[2,   800] loss: 0.699\n",
      "[2,   900] loss: 0.615\n",
      "[2,  1000] loss: 0.557\n",
      "[2,  1100] loss: 0.554\n",
      "[2,  1200] loss: 0.475\n",
      "[3,   100] loss: 0.436\n",
      "[3,   200] loss: 0.417\n",
      "[3,   300] loss: 0.401\n",
      "[3,   400] loss: 0.370\n",
      "[3,   500] loss: 0.368\n",
      "[3,   600] loss: 0.345\n",
      "[3,   700] loss: 0.313\n",
      "[3,   800] loss: 0.319\n",
      "[3,   900] loss: 0.311\n",
      "[3,  1000] loss: 0.290\n",
      "[3,  1100] loss: 0.282\n",
      "[3,  1200] loss: 0.263\n",
      "[4,   100] loss: 0.242\n",
      "[4,   200] loss: 0.246\n",
      "[4,   300] loss: 0.249\n",
      "[4,   400] loss: 0.243\n",
      "[4,   500] loss: 0.247\n",
      "[4,   600] loss: 0.206\n",
      "[4,   700] loss: 0.218\n",
      "[4,   800] loss: 0.213\n",
      "[4,   900] loss: 0.218\n",
      "[4,  1000] loss: 0.190\n",
      "[4,  1100] loss: 0.199\n",
      "[4,  1200] loss: 0.173\n",
      "[5,   100] loss: 0.204\n",
      "[5,   200] loss: 0.189\n",
      "[5,   300] loss: 0.181\n",
      "[5,   400] loss: 0.177\n",
      "[5,   500] loss: 0.191\n",
      "[5,   600] loss: 0.154\n",
      "[5,   700] loss: 0.178\n",
      "[5,   800] loss: 0.172\n",
      "[5,   900] loss: 0.159\n",
      "[5,  1000] loss: 0.168\n",
      "[5,  1100] loss: 0.152\n",
      "[5,  1200] loss: 0.147\n",
      "[6,   100] loss: 0.155\n",
      "[6,   200] loss: 0.156\n",
      "[6,   300] loss: 0.148\n",
      "[6,   400] loss: 0.132\n",
      "[6,   500] loss: 0.150\n",
      "[6,   600] loss: 0.166\n",
      "[6,   700] loss: 0.140\n",
      "[6,   800] loss: 0.140\n",
      "[6,   900] loss: 0.137\n",
      "[6,  1000] loss: 0.134\n",
      "[6,  1100] loss: 0.138\n",
      "[6,  1200] loss: 0.134\n",
      "Finished Training. Final loss = 0.18537697196006775, Total params = 38150\n",
      "[1,   100] loss: 2.309\n",
      "[1,   200] loss: 2.301\n",
      "[1,   300] loss: 2.298\n",
      "[1,   400] loss: 2.291\n",
      "[1,   500] loss: 2.283\n",
      "[1,   600] loss: 2.272\n",
      "[1,   700] loss: 2.254\n",
      "[1,   800] loss: 2.227\n",
      "[1,   900] loss: 2.163\n",
      "[1,  1000] loss: 2.038\n",
      "[1,  1100] loss: 1.740\n",
      "[1,  1200] loss: 1.312\n",
      "[2,   100] loss: 1.007\n",
      "[2,   200] loss: 0.833\n",
      "[2,   300] loss: 0.685\n",
      "[2,   400] loss: 0.615\n",
      "[2,   500] loss: 0.556\n",
      "[2,   600] loss: 0.519\n",
      "[2,   700] loss: 0.485\n",
      "[2,   800] loss: 0.447\n",
      "[2,   900] loss: 0.437\n",
      "[2,  1000] loss: 0.414\n",
      "[2,  1100] loss: 0.396\n",
      "[2,  1200] loss: 0.381\n",
      "[3,   100] loss: 0.347\n",
      "[3,   200] loss: 0.346\n",
      "[3,   300] loss: 0.332\n",
      "[3,   400] loss: 0.326\n",
      "[3,   500] loss: 0.309\n",
      "[3,   600] loss: 0.317\n",
      "[3,   700] loss: 0.298\n",
      "[3,   800] loss: 0.276\n",
      "[3,   900] loss: 0.266\n",
      "[3,  1000] loss: 0.250\n",
      "[3,  1100] loss: 0.258\n",
      "[3,  1200] loss: 0.285\n",
      "[4,   100] loss: 0.256\n",
      "[4,   200] loss: 0.245\n",
      "[4,   300] loss: 0.249\n",
      "[4,   400] loss: 0.242\n",
      "[4,   500] loss: 0.232\n",
      "[4,   600] loss: 0.217\n",
      "[4,   700] loss: 0.218\n",
      "[4,   800] loss: 0.223\n",
      "[4,   900] loss: 0.227\n",
      "[4,  1000] loss: 0.217\n",
      "[4,  1100] loss: 0.212\n",
      "[4,  1200] loss: 0.210\n",
      "[5,   100] loss: 0.198\n",
      "[5,   200] loss: 0.199\n",
      "[5,   300] loss: 0.204\n",
      "[5,   400] loss: 0.191\n",
      "[5,   500] loss: 0.193\n",
      "[5,   600] loss: 0.198\n",
      "[5,   700] loss: 0.186\n",
      "[5,   800] loss: 0.197\n",
      "[5,   900] loss: 0.184\n",
      "[5,  1000] loss: 0.173\n",
      "[5,  1100] loss: 0.182\n",
      "[5,  1200] loss: 0.167\n",
      "[6,   100] loss: 0.173\n",
      "[6,   200] loss: 0.182\n",
      "[6,   300] loss: 0.168\n",
      "[6,   400] loss: 0.162\n",
      "[6,   500] loss: 0.174\n",
      "[6,   600] loss: 0.152\n",
      "[6,   700] loss: 0.164\n",
      "[6,   800] loss: 0.161\n",
      "[6,   900] loss: 0.157\n",
      "[6,  1000] loss: 0.160\n",
      "[6,  1100] loss: 0.160\n",
      "[6,  1200] loss: 0.160\n",
      "Finished Training. Final loss = 0.20231595635414124, Total params = 9594\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "class CNNClassifier1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(128,256,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(256,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(128,64,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(64,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "class CNNClassifier2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(32,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(64,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(32,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "    \n",
    "class CNNClassifier3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,16,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(16,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(32,16,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(16,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "model1 = CNNClassifier1().to(device)\n",
    "model2 = CNNClassifier2().to(device)\n",
    "model3 = CNNClassifier3().to(device)\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "loss = None\n",
    "total_params = 0\n",
    "\n",
    "for name,param in model1.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model1(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "loss = None\n",
    "total_params = 0\n",
    "\n",
    "for name,param in model2.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model2(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "\n",
    "loss = None\n",
    "optimizer = optim.SGD(model3.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model3.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model3(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfeb891a-6f7a-4bf5-b9e2-5898f7f63ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7478a5f24200>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = [0.03902818262577057,0.08542836457490921,0.09705353528261185,0.06044217571616173]\n",
    "params = [601254,149798,38150,9594]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(params,losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0587c0-b4d4-476a-8b7c-d9e6a528346a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
